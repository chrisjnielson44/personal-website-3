---
title: "Building a Modular ML Risk API"
description: "How I designed and built a scalable machine learning backend for financial risk analysis at BNY."
date: "2024-06-15"
author: "Christopher Nielson"
tags: ["Machine Learning", "Python", "FastAPI", "Finance"]
published: true
---

Building production-ready machine learning systems is fundamentally different from prototyping models in notebooks. At BNY, I had the opportunity to architect and build a modular ML risk API that serves real-time predictions for financial risk analysis. Here's what I learned along the way.

## The Challenge

Financial institutions need to assess risk in real-time across thousands of transactions. Traditional batch processing approaches don't cut it when you need sub-second response times while maintaining model accuracy and regulatory compliance.

Our requirements were clear:
- **Low latency**: < 100ms p99 response times
- **High throughput**: Handle 10,000+ requests per second
- **Modularity**: Easy to swap models and feature pipelines
- **Observability**: Full audit trail for regulatory compliance

## Architecture Overview

The system follows a clean separation of concerns:

```python
# Core prediction interface
class RiskPredictor(Protocol):
    async def predict(self, features: FeatureSet) -> RiskScore:
        ...

# Modular feature extraction
class FeaturePipeline:
    def __init__(self, extractors: list[FeatureExtractor]):
        self.extractors = extractors
    
    async def extract(self, request: RiskRequest) -> FeatureSet:
        features = await asyncio.gather(
            *[ext.extract(request) for ext in self.extractors]
        )
        return FeatureSet.merge(features)
```

This design allows us to independently version and deploy feature extractors, making A/B testing and gradual rollouts straightforward.

## Key Design Decisions

### 1. Async-First Architecture

FastAPI's async support was crucial. By making all I/O operations async, we maximized throughput without spinning up hundreds of worker processes:

```python
@app.post("/predict")
async def predict_risk(request: RiskRequest) -> RiskResponse:
    features = await feature_pipeline.extract(request)
    score = await model.predict(features)
    await audit_log.record(request, score)
    return RiskResponse(score=score)
```

### 2. Model Versioning with MLflow

We integrated MLflow for model versioning and deployment. Each model is tagged with performance metrics, and rollbacks are as simple as changing a configuration value:

```python
class ModelRegistry:
    def __init__(self, mlflow_uri: str):
        self.client = MlflowClient(mlflow_uri)
    
    async def load_model(self, name: str, stage: str = "Production"):
        model_uri = f"models:/{name}/{stage}"
        return mlflow.pyfunc.load_model(model_uri)
```

### 3. Feature Store Integration

Rather than computing features on every request, we maintain a feature store with pre-computed values that update in near real-time. This dramatically reduced latency for complex feature calculations.

## Lessons Learned

1. **Start with observability**: We instrumented everything from day one. When issues arose in production, we could trace exactly what happened.

2. **Design for failure**: Circuit breakers, fallback models, and graceful degradation are essential in financial systems.

3. **Test with production-like data**: Synthetic data doesn't capture the edge cases you'll encounter with real financial instruments.

4. **Document decisions**: Financial systems require extensive documentation for auditors. Making this part of the development process, not an afterthought, saved countless hours.

## Results

After six months in production:
- **99.9% uptime** with zero critical incidents
- **45ms average latency** (well under our 100ms target)
- **30% improvement** in risk detection accuracy compared to the previous system

Building ML systems for finance taught me that the model is often the easy partâ€”the real challenge is everything around it.